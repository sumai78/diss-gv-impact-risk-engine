# -*- coding: utf-8 -*-
"""01_clean_features.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wqpbBfGgM9nIhzB6jS_O5pmoRs949J8A
"""

# STEP 1 Check that the zip file is correct

# show what is inside /content
!ls -lh /content

# check that archive2.zip is really a zip file
!file /content/archive2.zip

# STEP 2 – Reset project folders

import shutil, os

# delete old generated folders (NOT the zip file)
for p in ["data/raw/kiva_snapshot", "data/processed", "figures", "results"]:
    if os.path.exists(p):
        shutil.rmtree(p)

# create empty folders again
os.makedirs("data/raw/kiva_snapshot", exist_ok=True)
os.makedirs("data/processed", exist_ok=True)
os.makedirs("figures", exist_ok=True)
os.makedirs("results", exist_ok=True)

print("Reset done.")

# STEP 3 – Unzip the dataset safely
import os, zipfile, glob

# path to the uploaded dataset zip file
ZIP_PATH = "/content/archive2.zip"
# folder where the dataset will be extracted
EXTRACT_DIR = "data/raw/kiva_snapshot"

# create folder for extracted files
os.makedirs(EXTRACT_DIR, exist_ok=True)

# 2) Check that the zip file exists
# (prevents silent failure if the file is missing)
if not os.path.exists(ZIP_PATH):
    raise FileNotFoundError("archive2.zip not found in /content")

# unzip the file
with zipfile.ZipFile(ZIP_PATH, "r") as z:
    z.extractall(EXTRACT_DIR)

print("Extracted OK")

# find loans.csv inside extracted files
matches = glob.glob(os.path.join(EXTRACT_DIR, "**", "loans.csv"), recursive=True)
loans_csv_path = matches[0]
print("loans.csv path:", loans_csv_path)

# STEP 4 Clean and prepare the dataset

import pandas as pd
import matplotlib.pyplot as plt

# path where the cleaned dataset will be saved
OUT_CSV = "data/processed/kiva_processed.csv"

# 1) Load the raw loans.csv file extracted earlier
loans = pd.read_csv(loans_csv_path)

# 2) Keep only funded and expired loans (binary classification problem)
df = loans[loans["status"].isin(["funded", "expired"])].copy()
# Create binary target variable:
# 1 = funded, 0 = expired
df["y_funded"] = (df["status"] == "funded").astype(int)

# 3) Create a clean text column
# Prefer translated description if available
if "description_translated" in df.columns:
    df["text"] = (
        df["description_translated"].
        fillna(df["description"]).    # use original if translated is missing
        fillna("").astype(str)        # replace missing with empty text
    )
else:
    df["text"] = df["description"].fillna("").astype(str)
# Remove rows with very short or empty descriptions

df = df[df["text"].str.len() > 20].copy()
# 4) Select important input features for modelling
feature_cols = [
    "loan_amount","lender_term","sector_name","activity_name","country_name",
    "repayment_interval","borrower_pictured","borrower_genders","partner_id",
]

# keep loan_id for joining later (impact + decision rules)
keep_cols = ["loan_id", "status", "y_funded", "text"] + feature_cols
keep_cols = [c for c in keep_cols if c in df.columns]

# 5) Save the cleaned dataset for reproducibility
df_out = df[keep_cols].copy()
df_out.to_csv(OUT_CSV, index=False)

# 6) Create class distribution plot (funded vs expired)
counts = df_out["y_funded"].value_counts().reindex([0, 1], fill_value=0)
labels = ["Expired (0)", "Funded (1)"]

plt.figure()
plt.bar(labels, counts.values)
plt.title("Funded vs Expired class distribution")
plt.ylabel("Count")
plt.tight_layout()
plt.savefig("figures/class_distribution.png", dpi=300)
plt.close()

# 7) Print summary for report screenshots
print("Saved:", OUT_CSV)
print("Rows:", df_out.shape[0], "Cols:", df_out.shape[1])
print("Columns:", list(df_out.columns))
print("Class counts:", df_out["y_funded"].value_counts().to_dict())
print("Saved figure: figures/class_distribution.png")

# STEP 5 Check that the cleaned dataset was saved correctly
# show file size and confirm that kiva_processed.csv exists
!ls -lh data/processed/kiva_processed.csv

# REPORT SNAPSHOT (pasteable output for dissertation tables)

import os
import pandas as pd

DATA_PATH = "data/processed/kiva_processed.csv"   # repo-style
# fallback (if you previously saved it in /content)
FALLBACK_PATH = "/content/kiva_processed.csv"

path = DATA_PATH if os.path.exists(DATA_PATH) else FALLBACK_PATH

print("Using dataset:", path)
loans = pd.read_csv(path)

# --- Table 1 style: dataset filtering + cleaning log summary ---
print("\nTABLE 1 — Dataset summary (after filtering/cleaning)")
print("Rows:", loans.shape[0])
print("Columns:", loans.shape[1])
print("Columns list:", list(loans.columns))

# class distribution if available
if "y_funded" in loans.columns:
    print("Class counts (y_funded):", loans["y_funded"].value_counts().to_dict())

# loan_id check (traceability)
print("Has loan_id column:", "loan_id" in loans.columns)

# --- Table preview (for screenshot in appendix) ---
key_cols = ["loan_id", "status", "y_funded", "sector_name", "country_name", "loan_amount", "text"]
key_cols = [c for c in key_cols if c in loans.columns]

print("\nTABLE C.1 — Cleaned dataset preview (first 5 rows, key columns)")
print(loans[key_cols].head(5))