# -*- coding: utf-8 -*-
"""02_train_models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M18_gEVjfFAsR-47wP3SKER4ZLGIWnKa
"""

!cp /content/drive/MyDrive/01_clean_features.py /content/

!python 01_clean_features.py

# 02_train_logistic.py
# GreenVi$or — Baseline Logistic Regression viability model

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, classification_report
import matplotlib.pyplot as plt

# Load cleaned dataset created by 01_clean_features.py
DATA_PATH = "/content/kiva_processed.csv"
df = pd.read_csv(DATA_PATH)

# ----------------------------
# Features & target
# ----------------------------
target = "y_funded"

feature_cols = [
    "loan_amount",
    "lender_term",
    "sector_name",
    "activity_name",
    "country_name",
    "repayment_interval",
    "borrower_pictured",
    "borrower_genders",
    "partner_id",
]

X = df[feature_cols]
y = df[target]

num_cols = ["loan_amount", "lender_term", "partner_id"]
cat_cols = [c for c in feature_cols if c not in num_cols]

# ----------------------------
# Preprocessing
# ----------------------------
preprocess = ColumnTransformer(
    transformers=[
        ("num", Pipeline([("imp", SimpleImputer(strategy="median"))]), num_cols),
        ("cat", Pipeline([
            ("imp", SimpleImputer(strategy="most_frequent")),
            ("oh", OneHotEncoder(handle_unknown="ignore"))
        ]), cat_cols),
    ]
)

# ----------------------------
# Baseline Logistic Regression
# ----------------------------
model = Pipeline([
    ("prep", preprocess),
    ("clf", LogisticRegression(
        max_iter=3000,
        class_weight="balanced",
        solver="lbfgs"
    ))
])

# ----------------------------
# Train / test split
# ----------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

model.fit(X_train, y_train)

# ----------------------------
# Evaluation
# ----------------------------
proba = model.predict_proba(X_test)[:, 1]
pred = (proba >= 0.5).astype(int)

auc = roc_auc_score(y_test, proba)
print("ROC-AUC:", round(auc, 4))
print(classification_report(y_test, pred, digits=3))

# ----------------------------
# ROC Curve (for Figure 3)
# ----------------------------
from sklearn.metrics import roc_curve

fpr, tpr, _ = roc_curve(y_test, proba)

plt.figure()
plt.plot(fpr, tpr)
plt.plot([0,1],[0,1],'--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Logistic Regression ROC Curve")
plt.savefig("/content/roc_lr.png", dpi=200, bbox_inches="tight")
plt.close()

print("Saved ROC curve to /content/roc_lr.png")

# =========================================================
# Random Forest – Non-linear comparator (fast, sampled)
# =========================================================

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, classification_report, roc_curve
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Step 1: take a stratified sample to keep runtime reasonable
# We keep ALL expired (minority) and sample funded to match it (balanced).
df_exp = df[df["y_funded"] == 0]
df_fun = df[df["y_funded"] == 1].sample(n=len(df_exp), random_state=42)

df_rf = pd.concat([df_exp, df_fun]).sample(frac=1, random_state=42)  # shuffle

X_rf = df_rf[feature_cols]
y_rf = df_rf["y_funded"]

X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(
    X_rf, y_rf, test_size=0.2, stratify=y_rf, random_state=42
)

#  Step 2: Random Forest pipeline (same preprocessing as LR)
rf_model = Pipeline([
    ("prep", preprocess),
    ("clf", RandomForestClassifier(
        n_estimators=200,
        random_state=42,
        n_jobs=-1,
        class_weight="balanced_subsample"
    ))
])

rf_model.fit(X_train_rf, y_train_rf)

# Step 3: evaluation
rf_proba = rf_model.predict_proba(X_test_rf)[:, 1]
rf_pred = (rf_proba >= 0.5).astype(int)

rf_auc = roc_auc_score(y_test_rf, rf_proba)
print("Random Forest ROC-AUC (sampled):", round(rf_auc, 4))
print(classification_report(y_test_rf, rf_pred, digits=3))

#  Step 4: ROC curve image
fpr_rf, tpr_rf, _ = roc_curve(y_test_rf, rf_proba)

plt.figure()
plt.plot(fpr_rf, tpr_rf)
plt.plot([0,1],[0,1],'--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Random Forest ROC Curve (sampled)")
plt.savefig("/content/roc_rf.png", dpi=200, bbox_inches="tight")
plt.close()

print("Saved RF ROC curve to /content/roc_rf.png")

from sklearn.calibration import calibration_curve

# Logistic calibration
lr_prob_true, lr_prob_pred = calibration_curve(y_test, proba, n_bins=10)

plt.figure()
plt.plot(lr_prob_pred, lr_prob_true, marker='o')
plt.plot([0,1],[0,1],'--')
plt.xlabel("Predicted Probability")
plt.ylabel("Observed Frequency")
plt.title("Logistic Regression Calibration Curve")
plt.savefig("/content/calibration_lr.png", dpi=200, bbox_inches="tight")
plt.close()

# Random Forest calibration
rf_prob_true, rf_prob_pred = calibration_curve(y_test_rf, rf_proba, n_bins=10)

plt.figure()
plt.plot(rf_prob_pred, rf_prob_true, marker='o')
plt.plot([0,1],[0,1],'--')
plt.xlabel("Predicted Probability")
plt.ylabel("Observed Frequency")
plt.title("Random Forest Calibration Curve")
plt.savefig("/content/calibration_rf.png", dpi=200, bbox_inches="tight")
plt.close()

print("Saved calibration curves.")

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

img_lr = mpimg.imread("/content/calibration_lr.png")
img_rf = mpimg.imread("/content/calibration_rf.png")

plt.figure(figsize=(10,4))

plt.subplot(1,2,1)
plt.imshow(img_lr)
plt.axis("off")
plt.title("(a) Logistic Regression")

plt.subplot(1,2,2)
plt.imshow(img_rf)
plt.axis("off")
plt.title("(b) Random Forest (sampled)")

plt.tight_layout()
plt.savefig("/content/figure4_calibration_compare.png", dpi=200, bbox_inches="tight")
plt.close()

print("Saved Figure 4 to /content/figure4_calibration_compare.png")

from sklearn.metrics import confusion_matrix, average_precision_score

print("---- Logistic Regression (full test split) ----")
print("Confusion matrix:\n", confusion_matrix(y_test, pred))
print("PR-AUC for expired (treat expired as positive):", round(average_precision_score(1 - y_test, 1 - proba), 4))

print("\n---- Random Forest (sampled test split) ----")
print("Confusion matrix:\n", confusion_matrix(y_test_rf, rf_pred))
print("PR-AUC for expired (treat expired as positive):", round(average_precision_score(1 - y_test_rf, 1 - rf_proba), 4))